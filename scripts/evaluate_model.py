# evaluate_model.py - √âvaluation du mod√®le de classification des tumeurs c√©r√©brales

import os
import numpy as np
import tensorflow as tf
from sklearn.metrics import confusion_matrix, classification_report
import matplotlib.pyplot as plt
import seaborn as sns

# D√©finir les chemins dynamiquement
BASE_DIR = os.path.dirname(os.path.abspath(__file__))
TEST_DATA_PATH = os.path.join(BASE_DIR, "..", "data", "processed", "testing_data.npz")
MODEL_PATH = os.path.join(BASE_DIR, "..", "models", "final_model.keras")
OUTPUT_DIR = os.path.join(BASE_DIR, "..", "logs")

# Cr√©er le r√©pertoire de sortie s'il n'existe pas
os.makedirs(OUTPUT_DIR, exist_ok=True)

def load_testing_data(data_path):
    """
    Charge les donn√©es de test depuis un fichier .npz.
    Args:
        data_path (str): Chemin vers le fichier .npz contenant les donn√©es de test.
    Returns:
        X (numpy array): Images normalis√©es.
        y (numpy array): Labels r√©els encod√©s en one-hot.
        classes (list): Liste des noms des classes.
    """
    print(f"üìÇ Chargement des donn√©es de test depuis : {os.path.abspath(data_path)}")
    try:
        data = np.load(data_path)
        X = data['X']  # Normalisation des images
        y = data['y']
        classes = data['classes']
        print(f"‚úÖ Nombre d'images : {len(X)}, Classes : {classes}")
        return X, y, classes
    except FileNotFoundError:
        raise FileNotFoundError(f"‚ùå Fichier non trouv√© : {os.path.abspath(data_path)}")

def evaluate_model(model, X_test, y_test):
    """
    √âvalue le mod√®le sur les donn√©es de test.
    Args:
        model (tf.keras.Model): Mod√®le charg√© pour l'√©valuation.
        X_test (numpy array): Donn√©es de test.
        y_test (numpy array): Labels r√©els.
    Returns:
        y_pred (numpy array): Pr√©dictions du mod√®le.
        accuracy (float): Pr√©cision globale sur les donn√©es de test.
    """
    print("üß† √âvaluation du mod√®le...")

    # Ne pas convertir les labels en one-hot
    # Utiliser sparse_categorical_crossentropy
    loss, accuracy = model.evaluate(X_test, y_test, verbose=1)
    print(f"‚úÖ Pr√©cision sur les donn√©es de test : {accuracy:.2%}")
    
    # Pr√©dictions
    y_pred = np.argmax(model.predict(X_test), axis=1)
    return y_pred, accuracy

def plot_confusion_matrix(y_true, y_pred, classes, output_dir):
    """
    Affiche et sauvegarde la matrice de confusion.
    Args:
        y_true (numpy array): Labels r√©els.
        y_pred (numpy array): Pr√©dictions.
        classes (list): Noms des classes.
        output_dir (str): R√©pertoire pour sauvegarder la matrice.
    """
    cm = confusion_matrix(y_true, y_pred)
    plt.figure(figsize=(8, 6))
    sns.heatmap(cm, annot=True, fmt="d", cmap="Blues", xticklabels=classes, yticklabels=classes)
    plt.xlabel("Pr√©dictions")
    plt.ylabel("R√©el")
    plt.title("Matrice de Confusion")
    output_path = os.path.join(output_dir, "confusion_matrix.png")
    plt.savefig(output_path)
    plt.show()
    print(f"‚úÖ Matrice de confusion sauvegard√©e dans : {os.path.abspath(output_path)}")

def print_classification_report(y_true, y_pred, classes):
    """
    Affiche un rapport de classification d√©taill√©.
    Args:
        y_true (numpy array): Labels r√©els.
        y_pred (numpy array): Pr√©dictions.
        classes (list): Noms des classes.
    """
    report = classification_report(y_true, y_pred, target_names=classes)
    print("\nüìù Rapport de classification :\n")
    print(report)

def main():
    """
    Fonction principale pour charger les donn√©es de test, √©valuer le mod√®le et afficher les m√©triques.
    """
    # Charger les donn√©es de test
    X_test, y_test, classes = load_testing_data(TEST_DATA_PATH)
    
    # Charger le mod√®le sauvegard√©
    print(f"üìÇ Chargement du mod√®le depuis : {os.path.abspath(MODEL_PATH)}")
    try:
        model = tf.keras.models.load_model(MODEL_PATH)
    except FileNotFoundError:
        raise FileNotFoundError(f"‚ùå Mod√®le non trouv√© : {os.path.abspath(MODEL_PATH)}")
    
    # √âvaluer le mod√®le
    y_pred, accuracy = evaluate_model(model, X_test, y_test)
    
    # Afficher la matrice de confusion
    plot_confusion_matrix(y_test, y_pred, classes, OUTPUT_DIR)
    
    # Afficher le rapport de classification
    print_classification_report(y_test, y_pred, classes)

if __name__ == "__main__":
    main()
