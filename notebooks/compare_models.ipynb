{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Charger les données de test\n",
    "data = np.load(r\"C:\\Users\\HP\\Desktop\\brain-tumor-classification\\data\\processed\\testing_data.npz\")\n",
    "X_test, y_test, classes = data['X'], data['y'], data['classes']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chemins des modèles à comparer\n",
    "model_paths = {\n",
    "    \"Final Model\": r\"C:\\Users\\HP\\Desktop\\brain-tumor-classification\\models\\final_model.keras\",\n",
    "    \"VGG16\": r\"C:\\Users\\HP\\Desktop\\brain-tumor-classification\\models\\vgg16_model.keras\",\n",
    "    \"VGG19\": r\"C:\\Users\\HP\\Desktop\\brain-tumor-classification\\models\\vgg19_model.keras\",\n",
    "    \"ResNet50\": r\"C:\\Users\\HP\\Desktop\\brain-tumor-classification\\models\\resnet50_model.keras\"  # Assurez-vous que ce modèle existe\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Évaluation du modèle: Final Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\HP\\Desktop\\brain-tumor-classification\\venv\\Lib\\site-packages\\keras\\src\\saving\\saving_lib.py:757: UserWarning: Skipping variable loading for optimizer 'rmsprop', because it has 12 variables whereas the saved optimizer has 22 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 41ms/step\n",
      "📈 Accuracy: 0.96\n",
      "\n",
      "📝 Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      glioma       0.97      0.92      0.95       300\n",
      "  meningioma       0.91      0.92      0.92       306\n",
      "     notumor       0.98      1.00      0.99       405\n",
      "   pituitary       0.98      0.99      0.98       300\n",
      "\n",
      "    accuracy                           0.96      1311\n",
      "   macro avg       0.96      0.96      0.96      1311\n",
      "weighted avg       0.96      0.96      0.96      1311\n",
      "\n",
      "\n",
      "🔍 Évaluation du modèle: VGG16\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 1s/step\n",
      "📈 Accuracy: 0.94\n",
      "\n",
      "📝 Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      glioma       0.94      0.88      0.91       300\n",
      "  meningioma       0.87      0.89      0.88       306\n",
      "     notumor       0.99      1.00      0.99       405\n",
      "   pituitary       0.95      0.98      0.97       300\n",
      "\n",
      "    accuracy                           0.94      1311\n",
      "   macro avg       0.94      0.94      0.94      1311\n",
      "weighted avg       0.94      0.94      0.94      1311\n",
      "\n",
      "\n",
      "🔍 Évaluation du modèle: VGG19\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 2s/step\n",
      "📈 Accuracy: 0.93\n",
      "\n",
      "📝 Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      glioma       0.91      0.88      0.89       300\n",
      "  meningioma       0.87      0.85      0.86       306\n",
      "     notumor       0.97      0.99      0.98       405\n",
      "   pituitary       0.94      0.97      0.96       300\n",
      "\n",
      "    accuracy                           0.93      1311\n",
      "   macro avg       0.92      0.92      0.92      1311\n",
      "weighted avg       0.93      0.93      0.93      1311\n",
      "\n",
      "\n",
      "🔍 Évaluation du modèle: ResNet50\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 519ms/step\n",
      "📈 Accuracy: 0.98\n",
      "\n",
      "📝 Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      glioma       0.98      0.96      0.97       300\n",
      "  meningioma       0.95      0.95      0.95       306\n",
      "     notumor       0.98      1.00      0.99       405\n",
      "   pituitary       0.99      0.99      0.99       300\n",
      "\n",
      "    accuracy                           0.98      1311\n",
      "   macro avg       0.98      0.98      0.98      1311\n",
      "weighted avg       0.98      0.98      0.98      1311\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Initialiser un dictionnaire pour stocker les résultats\n",
    "results = {}\n",
    "\n",
    "# Boucle pour charger chaque modèle, faire des prédictions et calculer les métriques\n",
    "for model_name, model_path in model_paths.items():\n",
    "    print(f\"\\n🔍 Évaluation du modèle: {model_name}\")\n",
    "    \n",
    "    # Charger le modèle\n",
    "    model = tf.keras.models.load_model(model_path)\n",
    "    \n",
    "    # Faire des prédictions\n",
    "    preds = np.argmax(model.predict(X_test), axis=1)\n",
    "    \n",
    "    # Calculer l'accuracy\n",
    "    accuracy = accuracy_score(y_test, preds)\n",
    "    results[model_name] = accuracy\n",
    "    \n",
    "    # Afficher le rapport de classification\n",
    "    print(f\"📈 Accuracy: {accuracy:.2f}\")\n",
    "    print(\"\\n📝 Classification Report:\")\n",
    "    print(classification_report(y_test, preds, target_names=classes))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📊 **Résumé des Performances**\n",
      "Final Model: Accuracy = 0.96\n",
      "VGG16: Accuracy = 0.94\n",
      "VGG19: Accuracy = 0.93\n",
      "ResNet50: Accuracy = 0.98\n"
     ]
    }
   ],
   "source": [
    "# Résumé des résultats\n",
    "print(\"\\n📊 **Résumé des Performances**\")\n",
    "for model_name, accuracy in results.items():\n",
    "    print(f\"{model_name}: Accuracy = {accuracy:.2f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
